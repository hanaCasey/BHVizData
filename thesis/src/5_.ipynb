{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "import spacy\n",
    "import openai\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import plotly.express as px\n",
    "import ast\n",
    "import pdfkit\n",
    "import glob\n",
    "import os\n",
    "import chardet\n",
    "import base64\n",
    "import pdfkit\n",
    "from PyPDF2 import PdfMerger\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm.auto import tqdm\n",
    "from langdetect import detect, DetectorFactory\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from openai import OpenAI\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy import interpolate\n",
    "from PIL import Image, ImageDraw\n",
    "import multidict as multidict\n",
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora, models\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from random import sample \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input clusters internal user df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_i = pd.read_csv('exp/clusters_i.csv', encoding='utf-8', encoding_errors='replace')\n",
    "clusters_titles = clusters_i.titles\n",
    "\n",
    "# Contains titles and descriptions\n",
    "encoding = 'utf-8' \n",
    "embedding_i = pd.read_csv('../../../BHVizApp/src/data/internal_embedding.csv', encoding=encoding, encoding_errors='replace')\n",
    "\n",
    "clusters_i['top_titles'] = embedding_i.sort_values(['frequency_norm']).groupby('cluster').head(50).groupby('cluster').title.apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query OpenAI for title and description of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY= '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'\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_from_tokens(tokens):\n",
    "    try:\n",
    "        # print(tokens)\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Based on the titles of the books in this cluster of books from an art history library,come up with a meaningful title and a 100 word description of the cluster. Format of the response should be Title: Description. These are the titles: {tokens}\"}\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "        return completion.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = clusters_i.top_titles.apply(get_keywords_from_tokens)\n",
    "clusters_i['output'] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_titles (text): \n",
    "\n",
    "    split_text = text.split('\\n\\n')\n",
    "    title = split_text[0]\n",
    "    if(title.startswith('Title:')):\n",
    "        return(title[6:])\n",
    "    else: \n",
    "        return title\n",
    "\n",
    "def extract_descriptions(text): \n",
    "\n",
    "    split_text = text.split('\\n\\n')\n",
    "    description = split_text[1]\n",
    "    start = 'Description:'\n",
    "    if(description.startswith(start)):\n",
    "        return(description[len(start):])\n",
    "    else: \n",
    "        return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = clusters_i.output.apply(extract_titles)\n",
    "clusters_i['cluster_title'] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "descripions = clusters_i.output.apply(extract_descriptions)\n",
    "clusters_i['cluster_description'] = descripions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Atlas from titles and description\n",
    "\n",
    "Making one page per cluster with wordclouds and titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains titles and descriptions\n",
    "encoding = 'utf-8' \n",
    "embedding_i = pd.read_csv('../../../BHVizApp/src/data/internal_embedding.csv', encoding=encoding, encoding_errors='replace')\n",
    "\n",
    "# User loan data \n",
    "internal = pd.read_csv('exp/internal.csv')\n",
    "\n",
    "# cluster descriptions\n",
    "clusters_i = pd.read_csv('exp/clusters_i_extended.csv', encoding=encoding, encoding_errors='replace')\n",
    "clusters_i['top_titles'] = embedding_i.sort_values(['frequency_norm']).groupby('cluster').head(50).groupby('cluster').title.apply(list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# List of available stopwords \n",
    "english_stop_words = list(stopwords.words('english'))\n",
    "german_stop_words = list(stopwords.words('german'))\n",
    "italian_stop_words = list(stopwords.words('italian'))\n",
    "french_stop_words = list(stopwords.words('french'))\n",
    "\n",
    "wc = WordCloud( \n",
    "        mode = \"RGBA\",\n",
    "        color_func=lambda *args, **kwargs: (0, 0, 0),\n",
    "        font_path = path.join('Lato-Regular.ttf'),\n",
    "        # mask=mask,\n",
    "        normalize_plurals=False,\n",
    "        prefer_horizontal= 1,\n",
    "        margin=10,\n",
    "        background_color=None,\n",
    "        # background_color='black',\n",
    "        # max_words=max_words,\n",
    "        min_font_size= 5,\n",
    "        max_font_size= 100,\n",
    "        # collocation_threshold = 20,\n",
    "        relative_scaling = 1,\n",
    "    )\n",
    "\n",
    "# Generate Wordclouds for all clusters for the top 3 languages in each cluster\n",
    "clusters = embedding_i.groupby('cluster')\n",
    "\n",
    "for cluster_id, cluster in clusters:\n",
    "    nr_langs = 4\n",
    "    langs = cluster.groupby('lang').size().head(nr_langs).reset_index()['lang'].tolist()\n",
    "    lang_titles = cluster[cluster['lang'].isin(langs)].groupby('lang')\n",
    "\n",
    "    \n",
    "    for lang, lang_group in lang_titles:\n",
    "        # Remove stop words for main languages\n",
    "        if lang == 'eng':\n",
    "            stop_words = english_stop_words\n",
    "        elif lang == 'ger':\n",
    "            stop_words = german_stop_words\n",
    "        elif lang == 'ita':\n",
    "            stop_words = italian_stop_words\n",
    "        elif lang == 'fre':\n",
    "            stop_words = french_stop_words\n",
    "        else:\n",
    "            stop_words = None\n",
    "\n",
    "        # Apply stop words removal and tfidf vectorizer\n",
    "        titles = ' '.join(lang_group['title'].tolist())\n",
    "        vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "        tfidf_matrix = vectorizer.fit_transform([titles])\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "        # Generate word cloud\n",
    "        wc.generate_from_frequencies(dict(zip(feature_names, tfidf_matrix.toarray()[0])))\n",
    "        wc.to_file(path.join(\"exp/wc/\", f\"{cluster_id}_{lang}.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pdf_for_clusters(clusters):\n",
    "    for _,cluster in clusters.iterrows(): \n",
    "        cluster_id = cluster['cluster']\n",
    "        title = cluster['cluster_title']\n",
    "        description = cluster['cluster_description']\n",
    "        top_titles = cluster['top_titles']\n",
    "\n",
    "\n",
    "        image_pattern = f\"exp/wc/{cluster_id}_*.png\"\n",
    "        # image_paths = glob.glob(image_pattern) \n",
    "        image_paths = [os.path.abspath(image) for image in glob.glob(image_pattern)]\n",
    "\n",
    "        pdf_directory = \"exp/pdfs\"\n",
    "        pdf_filename = f\"{pdf_directory}/cluster_{cluster_id}_report.pdf\"\n",
    "\n",
    "        html_directory = \"exp/html\"\n",
    "        html_filename = f\"{html_directory}/cluster_{cluster_id}_report.html\"\n",
    "\n",
    "\n",
    "        # Create an HTML template for each cluster\n",
    "        html_template = f\"\"\"\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>{cluster_id} - {title}</title>\n",
    "            <style>\n",
    "            .container {{\n",
    "                display: flex;\n",
    "            }}\n",
    "            .left-column {{\n",
    "                flex: 1;\n",
    "            }}\n",
    "            .right-column {{\n",
    "                flex: 1;\n",
    "            }}\n",
    "            .image {{\n",
    "                margin-bottom: 20px; /* Add space below each image */\n",
    "            }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "                \n",
    "        <h1>{cluster_id} - {title}</h1>\n",
    "        <p>{description}</p>\n",
    "        <div class=\"container\">\n",
    "                <div class=\"left-column\">\n",
    "                <div class=\"image-container\">\n",
    "        \"\"\"\n",
    "\n",
    "        # Add images on the left side below the title and description\n",
    "        for image_path in image_paths[:4]:\n",
    "            if os.path.exists(image_path):\n",
    "                data_uri = base64.b64encode(open(image_path, 'rb').read()).decode('utf-8')\n",
    "                img_tag = '<img class=\"image\" src=\"data:image/png;base64,{0}\">'.format(data_uri)\n",
    "                html_template += img_tag\n",
    "            else:\n",
    "                print(f\"Image not found: {image_path}\")\n",
    "\n",
    "        html_template += \"\"\"\n",
    "                </div>\n",
    "            </div>\n",
    "            <div class=\"right-column\">\n",
    "                <ul>\n",
    "        \"\"\"\n",
    "\n",
    "        # Add the top titles to the right column\n",
    "        for top_title in top_titles:\n",
    "            html_template += f\"<li>{top_title}</li>\"\n",
    "\n",
    "        html_template += \"\"\"\n",
    "                </ul>\n",
    "            </div>\n",
    "        </div>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        options = {\n",
    "            'enable-local-file-access': None, \n",
    "        }\n",
    "        #         # Save the HTML content to a file\n",
    "        with open(html_filename, \"w\") as html_file:\n",
    "            html_file.write(html_template)\n",
    "\n",
    "        # Generate PDF for the cluster\n",
    "        # pdfkit.from_string(html_template, pdf_filename, options=options)\n",
    "\n",
    "generate_pdf_for_clusters(clusters_i, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing your HTML files\n",
    "html_directory = \"exp/html\"\n",
    "\n",
    "# Directory to save the final PDF\n",
    "output_pdf = \"exp/all_clusters_report.pdf\"\n",
    "html_files = [os.path.join(html_directory, filename) for filename in os.listdir(html_directory) if filename.endswith(\".html\")]\n",
    "\n",
    "css_directory = os.path.abspath('exp/example.css')\n",
    "\n",
    "options = {\n",
    "        'enable-local-file-access': True,\n",
    "        \"page-size\": \"A4\", \n",
    "        \"user-style-sheet\": css_directory \n",
    "    }\n",
    "\n",
    "pdf_files = []\n",
    "\n",
    "# Convert HTML files to separate PDFs\n",
    "for html_file in html_files:\n",
    "    pdf_file = os.path.splitext(html_file)[0] + \".pdf\"\n",
    "    pdfkit.from_file(html_file, pdf_file, options=options)\n",
    "    pdf_files.append(pdf_file)\n",
    "\n",
    "pdf_files = sorted(pdf_files, key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[1]))\n",
    "\n",
    "# Merge the individual PDFs into one PDF file\n",
    "merger = PdfMerger()\n",
    "for pdf_file in pdf_files:\n",
    "    merger.append(pdf_file)\n",
    "    \n",
    "# Save the merged PDF\n",
    "merger.write(output_pdf)\n",
    "merger.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_i[['cluster', 'x', 'y', 'nr_users', 'nr_books', 'cluster_title', 'cluster_description']].to_csv('exp/cluster_internal_info_2.csv', index=False)\n",
    "clusters_i.to_csv('exp/clusters_i_extended_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exp/html/cluster_0_report.pdf',\n",
       " 'exp/html/cluster_1_report.pdf',\n",
       " 'exp/html/cluster_2_report.pdf',\n",
       " 'exp/html/cluster_3_report.pdf',\n",
       " 'exp/html/cluster_4_report.pdf',\n",
       " 'exp/html/cluster_5_report.pdf',\n",
       " 'exp/html/cluster_6_report.pdf',\n",
       " 'exp/html/cluster_7_report.pdf',\n",
       " 'exp/html/cluster_8_report.pdf',\n",
       " 'exp/html/cluster_9_report.pdf',\n",
       " 'exp/html/cluster_10_report.pdf',\n",
       " 'exp/html/cluster_11_report.pdf',\n",
       " 'exp/html/cluster_12_report.pdf',\n",
       " 'exp/html/cluster_13_report.pdf',\n",
       " 'exp/html/cluster_14_report.pdf',\n",
       " 'exp/html/cluster_15_report.pdf',\n",
       " 'exp/html/cluster_16_report.pdf',\n",
       " 'exp/html/cluster_17_report.pdf',\n",
       " 'exp/html/cluster_18_report.pdf',\n",
       " 'exp/html/cluster_19_report.pdf',\n",
       " 'exp/html/cluster_20_report.pdf',\n",
       " 'exp/html/cluster_21_report.pdf',\n",
       " 'exp/html/cluster_22_report.pdf',\n",
       " 'exp/html/cluster_23_report.pdf',\n",
       " 'exp/html/cluster_24_report.pdf',\n",
       " 'exp/html/cluster_25_report.pdf',\n",
       " 'exp/html/cluster_26_report.pdf',\n",
       " 'exp/html/cluster_27_report.pdf',\n",
       " 'exp/html/cluster_28_report.pdf',\n",
       " 'exp/html/cluster_29_report.pdf',\n",
       " 'exp/html/cluster_30_report.pdf',\n",
       " 'exp/html/cluster_31_report.pdf',\n",
       " 'exp/html/cluster_32_report.pdf',\n",
       " 'exp/html/cluster_33_report.pdf',\n",
       " 'exp/html/cluster_34_report.pdf',\n",
       " 'exp/html/cluster_35_report.pdf',\n",
       " 'exp/html/cluster_36_report.pdf',\n",
       " 'exp/html/cluster_37_report.pdf',\n",
       " 'exp/html/cluster_38_report.pdf',\n",
       " 'exp/html/cluster_39_report.pdf',\n",
       " 'exp/html/cluster_40_report.pdf',\n",
       " 'exp/html/cluster_41_report.pdf',\n",
       " 'exp/html/cluster_42_report.pdf',\n",
       " 'exp/html/cluster_43_report.pdf',\n",
       " 'exp/html/cluster_44_report.pdf',\n",
       " 'exp/html/cluster_45_report.pdf',\n",
       " 'exp/html/cluster_46_report.pdf',\n",
       " 'exp/html/cluster_47_report.pdf',\n",
       " 'exp/html/cluster_48_report.pdf',\n",
       " 'exp/html/cluster_49_report.pdf',\n",
       " 'exp/html/cluster_50_report.pdf',\n",
       " 'exp/html/cluster_51_report.pdf',\n",
       " 'exp/html/cluster_52_report.pdf',\n",
       " 'exp/html/cluster_53_report.pdf',\n",
       " 'exp/html/cluster_54_report.pdf',\n",
       " 'exp/html/cluster_55_report.pdf',\n",
       " 'exp/html/cluster_56_report.pdf',\n",
       " 'exp/html/cluster_57_report.pdf',\n",
       " 'exp/html/cluster_58_report.pdf',\n",
       " 'exp/html/cluster_59_report.pdf',\n",
       " 'exp/html/cluster_60_report.pdf',\n",
       " 'exp/html/cluster_61_report.pdf',\n",
       " 'exp/html/cluster_62_report.pdf',\n",
       " 'exp/html/cluster_63_report.pdf',\n",
       " 'exp/html/cluster_64_report.pdf',\n",
       " 'exp/html/cluster_65_report.pdf',\n",
       " 'exp/html/cluster_66_report.pdf',\n",
       " 'exp/html/cluster_67_report.pdf',\n",
       " 'exp/html/cluster_68_report.pdf',\n",
       " 'exp/html/cluster_69_report.pdf',\n",
       " 'exp/html/cluster_70_report.pdf',\n",
       " 'exp/html/cluster_71_report.pdf',\n",
       " 'exp/html/cluster_72_report.pdf',\n",
       " 'exp/html/cluster_73_report.pdf',\n",
       " 'exp/html/cluster_74_report.pdf',\n",
       " 'exp/html/cluster_75_report.pdf',\n",
       " 'exp/html/cluster_76_report.pdf',\n",
       " 'exp/html/cluster_77_report.pdf',\n",
       " 'exp/html/cluster_78_report.pdf',\n",
       " 'exp/html/cluster_79_report.pdf',\n",
       " 'exp/html/cluster_80_report.pdf',\n",
       " 'exp/html/cluster_81_report.pdf',\n",
       " 'exp/html/cluster_82_report.pdf',\n",
       " 'exp/html/cluster_83_report.pdf',\n",
       " 'exp/html/cluster_84_report.pdf',\n",
       " 'exp/html/cluster_85_report.pdf',\n",
       " 'exp/html/cluster_86_report.pdf',\n",
       " 'exp/html/cluster_87_report.pdf',\n",
       " 'exp/html/cluster_88_report.pdf',\n",
       " 'exp/html/cluster_89_report.pdf',\n",
       " 'exp/html/cluster_90_report.pdf',\n",
       " 'exp/html/cluster_91_report.pdf',\n",
       " 'exp/html/cluster_92_report.pdf',\n",
       " 'exp/html/cluster_93_report.pdf',\n",
       " 'exp/html/cluster_94_report.pdf',\n",
       " 'exp/html/cluster_95_report.pdf',\n",
       " 'exp/html/cluster_96_report.pdf',\n",
       " 'exp/html/cluster_97_report.pdf',\n",
       " 'exp/html/cluster_98_report.pdf',\n",
       " 'exp/html/cluster_99_report.pdf',\n",
       " 'exp/html/cluster_100_report.pdf',\n",
       " 'exp/html/cluster_101_report.pdf',\n",
       " 'exp/html/cluster_102_report.pdf',\n",
       " 'exp/html/cluster_103_report.pdf',\n",
       " 'exp/html/cluster_104_report.pdf',\n",
       " 'exp/html/cluster_105_report.pdf',\n",
       " 'exp/html/cluster_106_report.pdf',\n",
       " 'exp/html/cluster_107_report.pdf',\n",
       " 'exp/html/cluster_108_report.pdf',\n",
       " 'exp/html/cluster_109_report.pdf',\n",
       " 'exp/html/cluster_110_report.pdf',\n",
       " 'exp/html/cluster_111_report.pdf',\n",
       " 'exp/html/cluster_112_report.pdf',\n",
       " 'exp/html/cluster_113_report.pdf',\n",
       " 'exp/html/cluster_114_report.pdf',\n",
       " 'exp/html/cluster_115_report.pdf',\n",
       " 'exp/html/cluster_116_report.pdf',\n",
       " 'exp/html/cluster_117_report.pdf',\n",
       " 'exp/html/cluster_118_report.pdf',\n",
       " 'exp/html/cluster_119_report.pdf',\n",
       " 'exp/html/cluster_120_report.pdf',\n",
       " 'exp/html/cluster_121_report.pdf',\n",
       " 'exp/html/cluster_122_report.pdf',\n",
       " 'exp/html/cluster_123_report.pdf',\n",
       " 'exp/html/cluster_124_report.pdf',\n",
       " 'exp/html/cluster_125_report.pdf',\n",
       " 'exp/html/cluster_126_report.pdf',\n",
       " 'exp/html/cluster_127_report.pdf',\n",
       " 'exp/html/cluster_128_report.pdf',\n",
       " 'exp/html/cluster_129_report.pdf',\n",
       " 'exp/html/cluster_130_report.pdf',\n",
       " 'exp/html/cluster_131_report.pdf',\n",
       " 'exp/html/cluster_132_report.pdf',\n",
       " 'exp/html/cluster_133_report.pdf',\n",
       " 'exp/html/cluster_134_report.pdf',\n",
       " 'exp/html/cluster_135_report.pdf',\n",
       " 'exp/html/cluster_136_report.pdf',\n",
       " 'exp/html/cluster_137_report.pdf',\n",
       " 'exp/html/cluster_138_report.pdf',\n",
       " 'exp/html/cluster_139_report.pdf',\n",
       " 'exp/html/cluster_140_report.pdf',\n",
       " 'exp/html/cluster_141_report.pdf',\n",
       " 'exp/html/cluster_142_report.pdf',\n",
       " 'exp/html/cluster_143_report.pdf',\n",
       " 'exp/html/cluster_144_report.pdf',\n",
       " 'exp/html/cluster_145_report.pdf',\n",
       " 'exp/html/cluster_146_report.pdf',\n",
       " 'exp/html/cluster_147_report.pdf',\n",
       " 'exp/html/cluster_148_report.pdf',\n",
       " 'exp/html/cluster_149_report.pdf',\n",
       " 'exp/html/cluster_150_report.pdf',\n",
       " 'exp/html/cluster_151_report.pdf',\n",
       " 'exp/html/cluster_152_report.pdf',\n",
       " 'exp/html/cluster_153_report.pdf',\n",
       " 'exp/html/cluster_154_report.pdf',\n",
       " 'exp/html/cluster_155_report.pdf',\n",
       " 'exp/html/cluster_156_report.pdf',\n",
       " 'exp/html/cluster_157_report.pdf',\n",
       " 'exp/html/cluster_158_report.pdf',\n",
       " 'exp/html/cluster_159_report.pdf',\n",
       " 'exp/html/cluster_160_report.pdf',\n",
       " 'exp/html/cluster_161_report.pdf',\n",
       " 'exp/html/cluster_162_report.pdf',\n",
       " 'exp/html/cluster_163_report.pdf',\n",
       " 'exp/html/cluster_164_report.pdf',\n",
       " 'exp/html/cluster_165_report.pdf',\n",
       " 'exp/html/cluster_166_report.pdf',\n",
       " 'exp/html/cluster_167_report.pdf',\n",
       " 'exp/html/cluster_168_report.pdf',\n",
       " 'exp/html/cluster_169_report.pdf',\n",
       " 'exp/html/cluster_170_report.pdf',\n",
       " 'exp/html/cluster_171_report.pdf',\n",
       " 'exp/html/cluster_172_report.pdf',\n",
       " 'exp/html/cluster_173_report.pdf',\n",
       " 'exp/html/cluster_174_report.pdf',\n",
       " 'exp/html/cluster_175_report.pdf',\n",
       " 'exp/html/cluster_176_report.pdf',\n",
       " 'exp/html/cluster_177_report.pdf',\n",
       " 'exp/html/cluster_178_report.pdf',\n",
       " 'exp/html/cluster_179_report.pdf',\n",
       " 'exp/html/cluster_180_report.pdf',\n",
       " 'exp/html/cluster_181_report.pdf',\n",
       " 'exp/html/cluster_182_report.pdf',\n",
       " 'exp/html/cluster_183_report.pdf',\n",
       " 'exp/html/cluster_184_report.pdf',\n",
       " 'exp/html/cluster_185_report.pdf',\n",
       " 'exp/html/cluster_186_report.pdf',\n",
       " 'exp/html/cluster_187_report.pdf',\n",
       " 'exp/html/cluster_188_report.pdf',\n",
       " 'exp/html/cluster_189_report.pdf',\n",
       " 'exp/html/cluster_190_report.pdf',\n",
       " 'exp/html/cluster_191_report.pdf',\n",
       " 'exp/html/cluster_192_report.pdf',\n",
       " 'exp/html/cluster_193_report.pdf',\n",
       " 'exp/html/cluster_194_report.pdf',\n",
       " 'exp/html/cluster_195_report.pdf',\n",
       " 'exp/html/cluster_196_report.pdf',\n",
       " 'exp/html/cluster_197_report.pdf',\n",
       " 'exp/html/cluster_198_report.pdf',\n",
       " 'exp/html/cluster_199_report.pdf',\n",
       " 'exp/html/cluster_200_report.pdf',\n",
       " 'exp/html/cluster_201_report.pdf',\n",
       " 'exp/html/cluster_202_report.pdf',\n",
       " 'exp/html/cluster_203_report.pdf',\n",
       " 'exp/html/cluster_204_report.pdf',\n",
       " 'exp/html/cluster_205_report.pdf',\n",
       " 'exp/html/cluster_206_report.pdf',\n",
       " 'exp/html/cluster_207_report.pdf',\n",
       " 'exp/html/cluster_208_report.pdf']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling on description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/hana/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')).union(set(stopwords.words('italian')))\n",
    "additional_remove = {'cluster', 'collection', 'art', 'artistic', 'like', 'art,', 'italy', 'italian', 'the', 'and', 'of', 'le'}\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    return [w for w in word_tokens if w.lower() not in stop_words and w.lower() not in additional_remove]\n",
    "\n",
    "clusters_i['processed_description'] = clusters_i['description'].apply(preprocess)\n",
    "grouped_descriptions = clusters_i['processed_description'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(grouped_descriptions)\n",
    "\n",
    "wc.generate_from_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"spans array critical perspectives cinema intersection politics , ideology , arts postwar contemporary times . includes analyses cultural conflicts societal transformations reflected film , works Pier Paolo Pasolini Cinecittà 's prominence . titles explore David Lynch 's influence , role voice sound cinema , nuances film fascist contexts . provides comprehensive examination landscape global connections represented interpreted cinematic lens , discussing narrative aesthetics , also broader socio-political resonances across different eras , including neorealism , Hollywood 's interactions cinema , portrayal diverse identities experiences European American film .\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_descriptions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = embedding_i.loc[embedding_i.cluster != -1].groupby('cluster')\n",
    "\n",
    "for super_cluster_id, group in grouped:\n",
    "    \n",
    "    scale = 10\n",
    "\n",
    "    min_X = group['x'].min() * scale\n",
    "    max_X = group['x'].max() * scale\n",
    "    min_Y = group['y'].min() * scale\n",
    "    max_Y = group['y'].max() * scale\n",
    "\n",
    "    width = (int)(max_X - min_X)\n",
    "    height = (int)(max_Y - min_Y)\n",
    "\n",
    "    points = [(row['x'] * scale - min_X, row['y'] * scale - min_Y) for index, row in group.iterrows()]\n",
    "\n",
    "    # Convex Hull\n",
    "    \n",
    "    if len(points) > 2:  # Convex Hull requires at least 3 points\n",
    "        hull = ConvexHull(points)\n",
    "        x_hull = np.append(hull.points[hull.vertices, 0], hull.points[hull.vertices, 0][0])\n",
    "        y_hull = np.append(hull.points[hull.vertices, 1], hull.points[hull.vertices, 1][0])\n",
    "\n",
    "    dist = np.sqrt((x_hull[:-1] - x_hull[1:])**2 + (y_hull[:-1] - y_hull[1:])**2)\n",
    "    dist_along = np.concatenate(([0], dist.cumsum()))\n",
    "    spline, u = interpolate.splprep([x_hull, y_hull], u=dist_along, s=0)\n",
    "    interp_d = np.linspace(dist_along[0], dist_along[-1], 50)\n",
    "    interp_x, interp_y = interpolate.splev(interp_d, spline)    \n",
    "    interp_points = list(zip(interp_x, interp_y))\n",
    "    \n",
    "\n",
    "    img = Image.new(mode = \"RGBA\", size = (width, height), color = (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    # draw.polygon(points, fill=(0,0,0))\n",
    "    draw.polygon(interp_points, fill=(0,0,0))\n",
    "    mask = np.array(img)\n",
    "\n",
    "    # text = ' '.join([' '.join(words) for words in group['processed_description']])\n",
    "\n",
    "    # print(super_cluster_id,text)\n",
    "\n",
    "    # dictionary = multidict.MultiDict()\n",
    "    # _dictionary = {}\n",
    "\n",
    "\n",
    "\n",
    "    # # Frequency\n",
    "\n",
    "    # for _word in text.split(\" \"):\n",
    "    #     val = _dictionary.get(_word, 0)\n",
    "    #     _dictionary[_word] = val + 1\n",
    "    # for key in _dictionary:\n",
    "    #     dictionary.add(key, _dictionary[key])\n",
    "\n",
    "    # # Wordcloud\n",
    "\n",
    "    # max_words = math.ceil(len(dictionary)*.01)  \n",
    "    word_scores = tfidf_scores[super_cluster_id]\n",
    "\n",
    "    wc = WordCloud( \n",
    "        mode = \"RGBA\",\n",
    "        color_func=lambda *args, **kwargs: (0, 0, 0),\n",
    "        font_path = path.join('Lato-Regular.ttf'),\n",
    "        mask=mask,\n",
    "        \n",
    "        normalize_plurals=False,\n",
    "        prefer_horizontal= 1,\n",
    "        \n",
    "        margin=10,\n",
    "\n",
    "        background_color=None,\n",
    "        # background_color='black',\n",
    "\n",
    "        # max_words=max_words,\n",
    "        \n",
    "        min_font_size= 5,\n",
    "        max_font_size= 100,\n",
    "        # collocation_threshold = 20,\n",
    "        relative_scaling = 1,\n",
    "    )\n",
    "    # print(super_cluster_id, max_words, '-', end=' ')\n",
    "\n",
    "    text = grouped_descriptions[super_cluster_id]\n",
    "    # wc.generate_from_frequencies(word_scores) # generate word cloud\n",
    "    wc.generate_from_text(text)\n",
    "    wc.to_file(path.join(\"../../../BHVizApp/src/wordclouds/\" + f\"{super_cluster_id:02}\" + \".png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cluster books , ensconced within art history library , offers comprehensive journey vibrant tapestry Italian art culture . collection ranges swathes biographies lexicons fine art , textiles , engravings , providing insights minutiae artistic expression ornaments . spans historical accounts papal influence since late Middle Ages , explores aesthetic theory medieval beauty postmodernism , delves Italian artistic phenomena Romanesque contemporary sculpture painting . Encyclopedias , drawing treatises , architecture manuals , scholarly interpretations iconography stand testaments Italy ’ rich artistic narrative . tomes also investigate religious architectures , mapping evolution , evidenced works city landscapes architectural marvels guided religious , mythological , classical iconographies . library becomes critical hub , enabling scholars connect dots artistry , aesthetics , history , myriad forces shaped Italian cultural heritage .'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bhviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
