{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signatures Processing\n",
    "\n",
    "In the following notebook, the signatures from the Bibliotheca Hertziana are decoded into several levels of meaning. \n",
    "Each Signature encodes not only the location of any given document in the library, but also it's content. \n",
    "The generic signatures are built like a tree with several levels:\n",
    "- Level 1: Encompasses all the documents that are about this broad topic: e.g. A -> Manuals\n",
    "\n",
    "    - Level 2: A subgroup of level 1, more specific: e.g. Aa -> Manuals -> General Manuals\n",
    "\n",
    "        - Level 3: A group of numbers with an overall topic: e.g. Aa 60 - 75 -> Bibliographies\n",
    "        \n",
    "            - Level 4: A specific number with the topic of the document: e.g. Aa 60 -> Bibliographies of Bibliographies (whatever that is...)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In this notebook, for each signature of the 'generic type' (as described above), the meaning of the signatures will be extracted and saved in a csv document. \n",
    "Additionally for some other 'non generic types' of signatures, i.e. People and Places, the same information structure will be created from the signatures. \n",
    "\n",
    "\n",
    "\n",
    "The generic type signatures and their meaning are taken from the excel sheets 'bhr1' and 'bhr2', which are internal library documents. \n",
    "The non generic types are decoded using an export of the SyCa database, where the librarians save newly allocated signatures. \n",
    "Some non generic type signatures (like A and B italian artists) have been added by hand\n",
    "\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the signature key in two parts\n",
    "\n",
    "df1 = pd.read_csv('data/bhr1.csv',  sep=';')\n",
    "columns = df1.columns\n",
    "df2 = pd.read_csv('data/bhr2.csv', names = columns, sep=';')\n",
    "\n",
    "#Concatenating\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('vw', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of the '...' in the texts\n",
    "df[\"text\"] = df[\"text\"].str.replace(r'\\.{3,}', '')\n",
    "\n",
    "# getting rid of \\n\n",
    "df['sys'] = df['sys'].str.replace('\\n', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backreferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace idem (=...) with the reference\n",
    "backreference = re.compile(r\"idem\\s*\\(\\s*=\\s*(.*)\\s*\\)\")\n",
    "\n",
    "df[\"backreference\"] = df[\"text\"].str.extract(backreference, expand=False)\n",
    "\n",
    "# Replaces the backreference with the first captured group\n",
    "df[\"text\"] = df[\"text\"].str.replace(backreference, r\"\\1\", regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the remaining idems\n",
    "idem = re.compile(r'\\bidem\\s*[,.]?\\s*')\n",
    "\n",
    "idem_df = df[df[\"text\"].str.contains(idem)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the idem without backreference by iterating over the rows directly above to find what it references\n",
    "\n",
    "for i, row in idem_df.iterrows():\n",
    "    # loop over rows in the df DataFrame above the current row\n",
    "    for j in range(i-1, -1, -1):\n",
    "        # No 'idem' in the row, then it contains the reference\n",
    "        if not idem.search(df.loc[j, \"text\"]):\n",
    "\n",
    "            #find the reference, first group before comma\n",
    "            reference = df.iloc[j].text.split(',')[0]\n",
    "            \n",
    "            #replace idem with the actual backreference\n",
    "            substring = df.iloc[i].text\n",
    "\n",
    "            modified_substring = idem.sub(f'{reference} ', substring)\n",
    "\n",
    "            df.loc[i, \"text\"] = modified_substring\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signature Tree\n",
    "Filling in the table with the meaning of the signatures for each level in the rows that belong to it.\n",
    "\n",
    "The structure acts like a tree, and in each leaf node we want the information from the nodes above.\n",
    ">A -> level 1 -> Manuals\n",
    "\n",
    ">Aa -> level 2 -> General Manuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to propagate the meaning of each signature level to the rows that belong to it \n",
    "def level_text (lev, text, df): \n",
    "    df[text]= ''\n",
    "\n",
    "    indices = df[df.lev == lev].index\n",
    "\n",
    "    for i in range(len(indices) -1): \n",
    "        #Iterate from this row to the next row with the same level, everything in between belongs to current category\n",
    "        start = indices[i]\n",
    "        end = indices[i+1] \n",
    "\n",
    "        # add level to all rows below in the tree\n",
    "        df.loc[start + 1 :end - 1, text][df.lev >= lev] = df.iloc[start].text\n",
    "\n",
    "    #handle the last case seperately \n",
    "    if len(indices) > 0: \n",
    "        start = indices[-1]\n",
    "        end = len(df)\n",
    "        df.loc[start + 1 :end - 1, text][df.lev >= lev]  = df.iloc[start].text\n",
    "\n",
    "# There are 1-5 levels for any given signature\n",
    "for i in range(1, 5): \n",
    "    level_text(i, 'text_' + str(i), df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranges\n",
    "\n",
    "Numbis column contains the identifiers for rows with consecutive signatures, but the same meaning/category\n",
    "\n",
    "For lookup operations, it's simpler to have each signature instead of ranges, so the rows with signatures extracted from the ranges are appended to the end of the df.\n",
    "\n",
    "The rows are appended to the end and not just after the row where the range was mentioned for efficiency reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending all the ranges as rows, to make lookup operations easier later\n",
    "df.numbis = df.numbis.fillna('')\n",
    "range_rows = df[df.numbis.str.isdigit()]\n",
    "\n",
    "for i, row in range_rows.iterrows():\n",
    "\n",
    "    start = int(re.findall(r'\\d+', row.sys)[0])\n",
    "    end = int(row.numbis)\n",
    "\n",
    "    for j in range(start, end): \n",
    "        new_row = row.copy()\n",
    "        new_row['sys'] = new_row['sys'].replace(str(start), str(j+1))\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('data/csv/signatures.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/csv/signatures.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with SyCa database\n",
    "Database containing the newly allocated signatures, mostly artists and Topography. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "syca = pd.read_csv('data/csv/signatures_C_E.csv', sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse People (C, W, Z; Hh)\n",
    "\n",
    "The Signatures starting with C, W, Z, Hh respectively contain artists and other people. The signatures have a different pattern than the generic ones, as they contain the first three letters of the name of the person (e.g. BER for BERnini). \n",
    "\n",
    ">The generic artists (C and W) have only one number allocated to their name (e.g. Ca-ABB 70 -> Abbate, Niccolo dell')\n",
    "\n",
    ">For A and B List artists, there are multiple numbers allocated, each containing a specific part of the literature concerning this artist (e.g. Ca-VER 1340 -> Bibliographies for VERonese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "rows = []\n",
    "\n",
    "artist_rows = syca[syca.sign.str.startswith('C', 'W') | syca.sign.str.startswith('Z')]\n",
    "\n",
    "def parse_artists(row):\n",
    "        field = row.sign\n",
    "        name = row['name']\n",
    "        if field.startswith('C'): \n",
    "            if len(field) > 1 and field[1] == 'a':\n",
    "                return 'Italienische Künstler', 'Alte Künstler (geboren vor 1870)', name\n",
    "            if len(field) > 1 and field[1] == 'm':\n",
    "                return 'Italienische Künstler', 'Moderne Künstler (geboren nach 1870)', name\n",
    "            if len(field) > 1 and field[1] == 'f':\n",
    "                return 'Italienische Künstler', 'Filmschaffende', name\n",
    "            else:\n",
    "               return None, None, None\n",
    "        elif field.startswith('W'): \n",
    "            if len(field) > 1 and field[1] == 'a':\n",
    "               return 'Ausseritalienische Künstler', 'Alte Künstler (geboren vor 1870)', name\n",
    "            if len(field) > 1 and field[1] == 'm':\n",
    "               return 'Ausseritalienische Künstler', 'Moderne Künstler (geboren nach 1870)', name\n",
    "            if len(field) > 1 and field[1] == 'f':\n",
    "                return 'Ausseritalienische Künstler', 'Filmschaffende', name\n",
    "            else:\n",
    "                return None, None, None\n",
    "        elif field.startswith('Z'): \n",
    "            if len(field) > 1 and field[1] == 'o':\n",
    "               return 'Nachbarwissenschaften', 'Italienische Dichter und ihre Werke', name\n",
    "            if len(field) > 1 and field[1] == 'p':\n",
    "               return 'Nachbarwissenschaften', 'Aussertalienische Dichter und ihre Werke', name\n",
    "            if len(field) > 1 and field[1] == 's':\n",
    "                return 'Nachbarwissenschaften', 'Werkausgaben zur Philosophie, Pädagogik und anderen geisteswissenschaftlichen Disziplinen', name\n",
    "            if len(field) > 1 and field[1] == 'u':\n",
    "                return 'Nachbarwissenschaften', 'Werkausgaben zur Theologie und religiöse Devotionsschriften', name\n",
    "        else: \n",
    "            return '', '', ''\n",
    "        \n",
    "\n",
    "# Mapping a and b artists to the start number of their signature\n",
    "\n",
    "a_artists = {'Bernini': 1920, 'Giotto': 660, 'Leonardo Da Vinci': 220, 'Michelangelo': 20, 'Raffael': 140, 'Tiepolo, Giov. Batt.': 10, 'Tiziano': 10}\n",
    "b_artists = {'Angelico (Fra Angelico)': 310, 'Bellini, Giovanni': 770, 'Borromini': 530, 'Boticelli': 180, 'Bramante': 270, 'Canaletto, Bernardo': 110,\n",
    "             'Canova': 980, 'Caravaggio': 316, 'Cellini': 290, 'Correggio': 1080, 'Donatello': 70, 'Duccio di Buoninsegna': 90,\n",
    "             'Franceschi, Piero': 250, 'Ghiberti, Lorenzo': 40, 'Ghirlandaio': 350, 'Giorgione': 580, 'Guardi, Francesco': 320, \n",
    "             'Mantegna': 980, 'Masaccio': 20, 'Palladio': 320, 'Perugino': 1200 ,'Reni, Guido': 70, 'Tintoretto, Jacopo': 220, 'Veronese': 670}\n",
    "\n",
    "# Generic artists in C, W and Z\n",
    "\n",
    "for i, row in artist_rows.iterrows():\n",
    "    text_1, text_2, text_3 = parse_artists(row)\n",
    "    sys = row.sign + ' ' + str(row.nr)\n",
    "    new_row = {'lev': 3, 'sys': sys, 'text': text_3, 'text_1': text_1, 'text_2': text_2}\n",
    "    rows.append(new_row)\n",
    "\n",
    "# A artists\n",
    "\n",
    "for a, start in a_artists.items():\n",
    "    sys = 'Ca-' + a[:3].upper() + ' '\n",
    "    rows += [{'lev': 3, 'sys': sys, 'text': a, 'text_2': 'Alte Künstler (geboren vor 1870)', 'text_1': 'Italienische Künstler'}]\n",
    "    rows += [{'lev': 4, 'sys': sys + str(start+i), 'text': t, 'text_3': a, 'text_2': 'Alte Künstler (geboren vor 1870)', 'text_1': 'Italienische Künstler'} \n",
    "            for i, t in enumerate(['Bibliographien', 'Quellenpublikationen', 'Sammelschriften', 'Ausstellungskataloge', \n",
    "                                   'Vollbiographien und Oeuvreverzeichnisse des Gesamtlebenswerkes', 'Teilbiographien und Oeuvreverzeichnisse einzelner Arbeitsperioden', \n",
    "                                   'Teilbiographien und Oeuvreverzeichnisse einzelner Arbeitsgebiete', 'Werkmonographien', 'Einzelfragen'], start=start)]\n",
    "# B artists\n",
    "\n",
    "for b, start in b_artists.items(): \n",
    "    sys = 'Ca-' + b[:3].upper() + ' '\n",
    "    rows += [{'lev': 3, 'sys': sys, 'text': b, 'text_2': 'Alte Künstler (geboren vor 1870)', 'text_1': 'Italienische Künstler'}]\n",
    "    rows += [{'lev': 4, 'sys': sys + str(start+i), 'text': t, 'text_3': a, 'text_2': 'Alte Künstler (geboren vor 1870)', 'text_1': 'Italienische Künstler'}\n",
    "              for i,t in enumerate(['Bibliographien, Quellenpublikationen', 'Sammelschriften, Ausstellungskataloge, Voll- und Teilbiografien (Arbeitsperioden und gebiete)', 'Werkmonographien, Einzelfragen'], start=start)]\n",
    "\n",
    "\n",
    "\n",
    "artists = pd.concat([artists, pd.DataFrame(rows)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, artists], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/csv/sig_with_artists.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topography parsing (E, X, Y)\n",
    "\n",
    "The Topographies are similar to the people, as they contain Level 1 (and 2) identifiers (e.g. 'E' or 'Xa') followed by the first three letters of the place (e.g. BOL -> BOLogna).\n",
    "The letters are followed by a set of numbers, *ALWAYS* starting with an odd one, which contains the art-historical literature, and the following even number contains the non-art historical literature.\n",
    "\n",
    "\n",
    ">E contains italian topography\n",
    ">> For italy there is a list of special cities with more numbers allocated (see it_cities further down)\n",
    "\n",
    ">X contains European topography\n",
    ">> The names are from a different century, the reader has been warned\n",
    "\n",
    ">Y contains topography outside of Europe\n",
    ">> The same warning as for Europe applies here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/xb9k_3m95gq0wjgk1kgw1nxr0000gn/T/ipykernel_11464/3891623172.py:1: DtypeWarning: Columns (2,4,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/csv/sig_with_artists.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/csv/sig_with_artists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic topographies in Italy\n",
    "\n",
    "topographies = pd.DataFrame(columns=df.columns)\n",
    "rows = []\n",
    "\n",
    "topo_rows_italy = syca[syca.sign.str.startswith('E')]\n",
    "\n",
    "for i, row in topo_rows_italy.iterrows():\n",
    "\n",
    "    # start should be odd, if it's even then start = nr - 1\n",
    "    start = row.nr\n",
    "    if start % 2 == 0: \n",
    "        start -= 1\n",
    "    \n",
    "    sys = row.sign + ' ' + str(start)\n",
    "    new_row_odd = {'lev': 3, 'sys': sys, 'text': 'nicht-kunstgeschichtliche Literatur', 'text_1': 'Topographie Italien (ohne Rom)', 'text_2': row['name']}\n",
    "    rows.append(new_row_odd)\n",
    "\n",
    "    sys = row.sign + ' ' + str(start + 1)\n",
    "    new_row_even = {'lev': 3, 'sys': sys, 'text': 'kunstgeschichtliche Literatur', 'text_1': 'Topographie Italien (ohne Rom)', 'text_2': row['name']}\n",
    "    rows.append(new_row_even)\n",
    "\n",
    "topographies = pd.concat([topographies, pd.DataFrame(rows)], ignore_index=True)\n",
    "\n",
    "# Topographies in Europe: \n",
    "\n",
    "X_topos = {\n",
    "  'Xa': 'Deutschland',\n",
    "  'Xb': 'Österreich',\n",
    "  'Xc': 'Schweiz und Lichtenstein',\n",
    "  'Xd': 'Frankreich und Monaco',\n",
    "  'Xe': 'Belgien',\n",
    "  'Xf': 'Holland',\n",
    "  'Xg': 'Luxemburg',\n",
    "  'Xh': 'Grossbritannien und Irland',\n",
    "  'Xi': 'Spanien mit Gibraltar und Andorra',\n",
    "  'Xk': 'Portugal',\n",
    "  'Xl': 'Dänemark und Island',\n",
    "  'Xm': 'Schweden',\n",
    "  'Xn': 'Norwegen',\n",
    "  'Xo': 'Finnland',\n",
    "  'Xp': 'Tschechoslowakei',\n",
    "  'Xq': 'Polen',\n",
    "  'Xr': 'Europäische Sowjetunion (einschließlich baltische Staaten)',\n",
    "  'Xs': 'Ungarn',\n",
    "  'Xt': 'Jugoslawien und Albanien',\n",
    "  'Xu': 'Bulgarien',\n",
    "  'Xw': 'Rumänien',\n",
    "  'Xx': 'Griechenland (mit Rhodos) und Zypern',\n",
    "  'Xy': 'Europäische Türkei'\n",
    "}\n",
    "\n",
    "rows = []\n",
    "topo_rows_europe = syca[syca.sign.str.startswith('X')]\n",
    "\n",
    "for i, row in topo_rows_europe.iterrows():\n",
    "\n",
    "    # start should be odd, if it's even then start = nr - 1\n",
    "    start = row.nr\n",
    "    if start % 2 == 0: \n",
    "        start -= 1\n",
    "    \n",
    "    country = X_topos[row.sign[:2]]\n",
    "\n",
    "    sys = row.sign + ' ' + str(start)\n",
    "    new_row_odd = {'lev': 4, 'sys': sys, 'text': 'nicht-kunstgeschichtliche Literatur', 'text_1': 'Topographie Europa (ohne Italien)', 'text_2': country, 'text_3': row['name']}\n",
    "    rows.append(new_row_odd)\n",
    "\n",
    "    sys = row.sign + ' ' + str(start + 1)\n",
    "    new_row_even = {'lev': 4, 'sys': sys, 'text': 'kunstgeschichtliche Literatur', 'text_1': 'Topographie Europa (ohne Italien)', 'text_2': country, 'text_3': row['name']}\n",
    "    rows.append(new_row_even)\n",
    "\n",
    "topographies = pd.concat([topographies, pd.DataFrame(rows)], ignore_index=True)\n",
    "\n",
    "\n",
    "# Topographies not in Europe: \n",
    "\n",
    "Y_topos = {\n",
    "  'Ya': 'Asiatische Türkei',\n",
    "  'Yb': 'Syrien und Libanon',\n",
    "  'Yc': 'Israel und Jordanien',\n",
    "  'Ye': 'Saudi-Arabien mit Jemen, Aden und Oman',\n",
    "  'Yf': 'Irak',\n",
    "  'Yg': 'Iran (Persien)',\n",
    "  'Yh': 'Afghanistan',\n",
    "  'Yi': 'Indien, Pakistan und Nepal',\n",
    "  'Yk': 'hinterindische Staaten (Burma, Thailand, Kambodscha, Vietnam etc.)',\n",
    "  'Yl': 'Japan',\n",
    "  'Ym': 'China',\n",
    "  'Yn': 'asiatische Sowjetunion',\n",
    "  'Yo': 'malaiische Inseln und Ozeanien (Südsee-Inseln)',\n",
    "  'Yp': 'Ägypten',\n",
    "  'Yq': 'Abessinien',\n",
    "  'Yr': 'übrige nordafrikanische Staaten (Libyen mit Cyrenaica und Tripolitanien, Tunesien, Algerien, Marokko)',\n",
    "  'Ys': 'mittel- und südafrikanische Staaten',\n",
    "  'Yt': 'Kanada',\n",
    "  'Yu': 'USA',\n",
    "  'Yw': 'Mexiko',\n",
    "  'Yx': 'Mittelamerika (Guatemala, Honduras, Salvador, Nicaragua, Costa Rica, Panama und die Inseln des Karibischen Meeres)',\n",
    "  'Yy': 'Südamerika (Kolumbien, Venezuela, Guayana, Ecuador, Peru, Brasilien, Bolivien, Paraguay, Uruguay, Argentinien, Chile)',\n",
    "  'Yz': 'Australien mit Neuseeland'\n",
    "}\n",
    "\n",
    "rows = []\n",
    "topo_rows_world = syca[syca.sign.str.startswith('Y')]\n",
    "\n",
    "for i, row in topo_rows_world.iterrows():\n",
    "\n",
    "    # start should be odd, if it's even then start = nr - 1\n",
    "    start = row.nr\n",
    "    if start % 2 == 0: \n",
    "        start -= 1\n",
    "    \n",
    "    country = Y_topos[row.sign[:2]]\n",
    "\n",
    "    sys = row.sign + ' ' + str(start)\n",
    "    new_row_odd = {'lev': 4, 'sys': sys, 'text': 'nicht-kunstgeschichtliche Literatur', 'text_1': 'Topographie Europa (ohne Italien)', 'text_2': country, 'text_3': row['name']}\n",
    "    rows.append(new_row_odd)\n",
    "\n",
    "    sys = row.sign + ' ' + str(start + 1)\n",
    "    new_row_even = {'lev': 4, 'sys': sys, 'text': 'kunstgeschichtliche Literatur', 'text_1': 'Topographie Europa (ohne Italien)', 'text_2': country, 'text_3': row['name']}\n",
    "    rows.append(new_row_even)\n",
    "\n",
    "topographies = pd.concat([topographies, pd.DataFrame(rows)], ignore_index=True)\n",
    "\n",
    "# Special cities in Italy\n",
    "rows = []\n",
    "\n",
    "it_cities = {\n",
    "    'Bologna': 60,\n",
    "    'Brescia': 290,\n",
    "    'Ferrara': 100,\n",
    "    'Genova': 60,\n",
    "    'Messina': 70,\n",
    "    'Milano': 10,\n",
    "    'Modena': 10,\n",
    "    'Napoli': 10,\n",
    "    'Padova': 90,\n",
    "    'Palermo': 240,\n",
    "    'Parma': 120,\n",
    "    'Perugia': 310,\n",
    "    'Pisa': 10,\n",
    "    'Ravenna': 50,\n",
    "    'Siena': 10,\n",
    "    'Torino': 120,\n",
    "    'Verona': 300\n",
    "}\n",
    "\n",
    "for city, start in it_cities.items():\n",
    "    \n",
    "    sys = 'E-' + city[:3].upper() + ' '\n",
    "    rows += [{'lev': 2, 'sys': sys, 'text': city, 'text_1': 'Topographie Italien (ohne Rom)'}]\n",
    "    rows += [{'lev': 3, 'sys': sys + str(start), 'text': t, 'text_2': city, 'text_1': 'Topographie Italien (ohne Rom)'} \n",
    "            for i, t in enumerate(['nicht-kunstgeschichtliche Literatur, Topographien und Bibliographien', 'Guiden', 'Kunst allgemein', 'Architektur', \n",
    "                                   'Plastik', 'Malerei, Grafik, Mosaik, Buchmalerei', \n",
    "                                   'Hauptkirche', 'sonstige einzelne Kirchen', 'einelne Profangebäude', 'Varia'], start=start)]\n",
    "\n",
    "topographies = pd.concat([topographies, pd.DataFrame(rows)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, topographies], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['text', 'text_1', 'text_2', 'text_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/csv/sig_updated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
